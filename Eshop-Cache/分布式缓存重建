
1、流量均匀分布到所有缓存服务实例上
应用层nginx，是将请求流量均匀地打到各个缓存服务实例中的，可能咱们的eshop-cache那个服务，
可能会部署多实例在不同的机器上

2、应用层nginx的hash，固定商品id，走固定的缓存服务实例

3、源信息服务发送的变更消息，需要按照商品id去分区，固定的商品变更走固定的kafka分区，
   也就是固定的一个缓存服务实例获取到
(1)缓存服务，是监听kafka topic的，一个缓存服务实例，作为一个kafka consumer，就消费topic中的一个partition
所以你有多个缓存服务实例的话，每个缓存服务实例就消费一个kafka partition
所以这里，一般来说，你的源头信息服务，在发送消息到kafka topic的时候，都需要按照product id去分区
也就时说，同一个product id变更的消息一定是到同一个kafka partition中去的，
(2)也就是说同一个product id的变更消息，一定是同一个缓存服务实例消费到的
(3)我们也不去做了，其实很简单，kafka producer api，里面send message的时候，多加一个参数就可以了，
product id传递进去，就可以了

4、问题是，自己写的简易的hash分发，与kafka的分区，可能并不一致！！！
(1)我们自己写的简易的hash分发策略，是按照crc32去取hash值，然后再取模的
(2)关键你又不知道你的kafka producer的hash策略是什么，很可能说跟我们的策略是不一样的
拿就可能导致说，数据变更的消息所到的缓存服务实例，
(3)跟我们的应用层nginx分发到的那个缓存服务实例也许就不在一台机器上了
这样的话，在高并发，极端的情况下，可能就会出现冲突




